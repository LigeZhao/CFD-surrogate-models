{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d4cfd0f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45, 3)\n",
      "(45, 4096)\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from optuna.integration import TFKerasPruningCallback\n",
    "from optuna.trial import TrialState\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import logging\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "import math\n",
    "\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "tf.autograph.set_verbosity(0)\n",
    "\n",
    "datapath = 'data\\\\reduced_temperature_data.xlsx'\n",
    "\n",
    "X_data = np.array(pd.read_excel(datapath, sheet_name = 'boundary_condition'))\n",
    "Y_data = np.transpose(np.array(pd.read_excel(datapath, sheet_name = 'temperature')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e4b54b47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-17 18:17:17,048] A new study created in RDB with name: CFD_ANN_opt\n",
      "[I 2024-03-17 18:17:19,326] Trial 0 finished with value: -0.023641930733292682 and parameters: {'n_layers': 5, 'n_units_0': 11, 'dropout_0': 0.4270865407692739, 'n_units_1': 7, 'dropout_1': 0.46333991010010234, 'n_units_2': 4, 'dropout_2': 0.19871889584609315, 'n_units_3': 39, 'dropout_3': 0.48544527568610174, 'n_units_4': 23, 'dropout_4': 0.37710155101970655, 'learning_rate': 0.0017789376943571546}. Best is trial 0 with value: -0.023641930733292682.\n",
      "[I 2024-03-17 18:18:07,914] Trial 1 finished with value: 0.6417287510882586 and parameters: {'n_layers': 5, 'n_units_0': 18, 'dropout_0': 0.47170642671550034, 'n_units_1': 14, 'dropout_1': 0.12973311098619122, 'n_units_2': 19, 'dropout_2': 0.13033129020211215, 'n_units_3': 62, 'dropout_3': 0.18397149620032477, 'n_units_4': 40, 'dropout_4': 0.2877075848857696, 'learning_rate': 0.00015336317499991815}. Best is trial 1 with value: 0.6417287510882586.\n",
      "[I 2024-03-17 18:18:12,927] Trial 2 finished with value: -0.22035035346804466 and parameters: {'n_layers': 1, 'n_units_0': 4, 'dropout_0': 0.45789404020849145, 'learning_rate': 2.604283370492831e-05}. Best is trial 1 with value: 0.6417287510882586.\n",
      "[I 2024-03-17 18:18:14,630] Trial 3 finished with value: -0.15799700244162151 and parameters: {'n_layers': 1, 'n_units_0': 32, 'dropout_0': 0.32830953363303117, 'learning_rate': 0.0005380417334315065}. Best is trial 1 with value: 0.6417287510882586.\n",
      "[I 2024-03-17 18:18:16,188] Trial 4 finished with value: -0.06645800114846057 and parameters: {'n_layers': 3, 'n_units_0': 4, 'dropout_0': 0.13147468485053027, 'n_units_1': 12, 'dropout_1': 0.18798644335881853, 'n_units_2': 5, 'dropout_2': 0.41883804627563626, 'learning_rate': 0.0034180997576490862}. Best is trial 1 with value: 0.6417287510882586.\n",
      "[I 2024-03-17 18:18:21,519] Trial 5 finished with value: -0.028678518143299803 and parameters: {'n_layers': 5, 'n_units_0': 42, 'dropout_0': 0.11485100437951985, 'n_units_1': 27, 'dropout_1': 0.4945043118620962, 'n_units_2': 31, 'dropout_2': 0.24851867069614153, 'n_units_3': 36, 'dropout_3': 0.23104123809608756, 'n_units_4': 14, 'dropout_4': 0.34596991860575277, 'learning_rate': 0.0002888128093972403}. Best is trial 1 with value: 0.6417287510882586.\n",
      "[I 2024-03-17 18:18:22,991] Trial 6 finished with value: 0.6528567597282819 and parameters: {'n_layers': 2, 'n_units_0': 61, 'dropout_0': 0.15422737496427308, 'n_units_1': 8, 'dropout_1': 0.2714009862738428, 'learning_rate': 0.025797897384097948}. Best is trial 6 with value: 0.6528567597282819.\n",
      "[I 2024-03-17 18:18:28,770] Trial 7 finished with value: -0.06609650985358617 and parameters: {'n_layers': 3, 'n_units_0': 9, 'dropout_0': 0.1552243236042291, 'n_units_1': 58, 'dropout_1': 0.14262112382954417, 'n_units_2': 51, 'dropout_2': 0.3073041330160587, 'learning_rate': 0.00013749326733989778}. Best is trial 6 with value: 0.6528567597282819.\n",
      "[I 2024-03-17 18:18:30,824] Trial 8 finished with value: 0.6045015417741013 and parameters: {'n_layers': 5, 'n_units_0': 9, 'dropout_0': 0.4856665293331315, 'n_units_1': 60, 'dropout_1': 0.25365258089736736, 'n_units_2': 5, 'dropout_2': 0.4199984941501945, 'n_units_3': 31, 'dropout_3': 0.11745776227099479, 'n_units_4': 15, 'dropout_4': 0.45341564599754214, 'learning_rate': 0.018656141411835078}. Best is trial 6 with value: 0.6528567597282819.\n",
      "[I 2024-03-17 18:19:09,748] Trial 9 finished with value: -0.1323079487259693 and parameters: {'n_layers': 5, 'n_units_0': 12, 'dropout_0': 0.22978238277187366, 'n_units_1': 7, 'dropout_1': 0.18527584264408012, 'n_units_2': 16, 'dropout_2': 0.12696663762649948, 'n_units_3': 6, 'dropout_3': 0.24291537356537118, 'n_units_4': 4, 'dropout_4': 0.2124680092978315, 'learning_rate': 2.291419115658564e-05}. Best is trial 6 with value: 0.6528567597282819.\n",
      "[I 2024-03-17 18:19:11,047] Trial 10 finished with value: 0.5961402843854963 and parameters: {'n_layers': 2, 'n_units_0': 64, 'dropout_0': 0.2263420600009528, 'n_units_1': 5, 'dropout_1': 0.3477197165598413, 'learning_rate': 0.08287777392949819}. Best is trial 6 with value: 0.6528567597282819.\n",
      "[I 2024-03-17 18:19:13,759] Trial 11 finished with value: 0.6271335986143183 and parameters: {'n_layers': 4, 'n_units_0': 21, 'dropout_0': 0.38399775686484816, 'n_units_1': 13, 'dropout_1': 0.10577342510666271, 'n_units_2': 15, 'dropout_2': 0.12204770091511039, 'n_units_3': 63, 'dropout_3': 0.10173917414172193, 'learning_rate': 0.008735502464955055}. Best is trial 6 with value: 0.6528567597282819.\n",
      "[I 2024-03-17 18:19:15,998] Trial 12 finished with value: -0.1303013774893904 and parameters: {'n_layers': 2, 'n_units_0': 23, 'dropout_0': 0.35184293258454646, 'n_units_1': 4, 'dropout_1': 0.2752077289617576, 'learning_rate': 0.0011681434327092397}. Best is trial 6 with value: 0.6528567597282819.\n",
      "[I 2024-03-17 18:19:21,015] Trial 13 finished with value: -0.11729134250505613 and parameters: {'n_layers': 2, 'n_units_0': 58, 'dropout_0': 0.27973553163141396, 'n_units_1': 20, 'dropout_1': 0.3409501109069012, 'learning_rate': 0.00016280358596197994}. Best is trial 6 with value: 0.6528567597282819.\n",
      "[I 2024-03-17 18:19:23,505] Trial 14 finished with value: 0.6248811425048062 and parameters: {'n_layers': 4, 'n_units_0': 39, 'dropout_0': 0.40794369117814766, 'n_units_1': 9, 'dropout_1': 0.10677486804420988, 'n_units_2': 13, 'dropout_2': 0.10495527178367034, 'n_units_3': 14, 'dropout_3': 0.3405792463673353, 'learning_rate': 0.07974635087867914}. Best is trial 6 with value: 0.6528567597282819.\n",
      "[I 2024-03-17 18:19:25,715] Trial 15 finished with value: 0.6297435702674279 and parameters: {'n_layers': 4, 'n_units_0': 19, 'dropout_0': 0.49496666220680097, 'n_units_1': 19, 'dropout_1': 0.20521561439312277, 'n_units_2': 55, 'dropout_2': 0.303611123744469, 'n_units_3': 15, 'dropout_3': 0.19939937239725353, 'learning_rate': 0.006134691450724691}. Best is trial 6 with value: 0.6528567597282819.\n",
      "[I 2024-03-17 18:19:27,191] Trial 16 finished with value: 0.652080125790168 and parameters: {'n_layers': 2, 'n_units_0': 35, 'dropout_0': 0.29477392272293446, 'n_units_1': 10, 'dropout_1': 0.2353322319909386, 'learning_rate': 0.02074885801545363}. Best is trial 6 with value: 0.6528567597282819.\n",
      "[I 2024-03-17 18:19:28,622] Trial 17 finished with value: 0.6053337590064773 and parameters: {'n_layers': 2, 'n_units_0': 48, 'dropout_0': 0.17833680182331024, 'n_units_1': 9, 'dropout_1': 0.25694886506464765, 'learning_rate': 0.021722008200714956}. Best is trial 6 with value: 0.6528567597282819.\n",
      "[I 2024-03-17 18:19:30,802] Trial 18 finished with value: 0.9787103471426636 and parameters: {'n_layers': 1, 'n_units_0': 29, 'dropout_0': 0.2750119831757307, 'learning_rate': 0.027988326072001492}. Best is trial 18 with value: 0.9787103471426636.\n",
      "[I 2024-03-17 18:19:32,902] Trial 19 finished with value: 0.977701661080342 and parameters: {'n_layers': 1, 'n_units_0': 28, 'dropout_0': 0.10256335056457958, 'learning_rate': 0.03559532333340388}. Best is trial 18 with value: 0.9787103471426636.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "best_value = 0.9787103471426636\n",
      "best_params:\n",
      "{'n_layers': 1, 'n_units_0': 29, 'dropout_0': 0.2750119831757307, 'learning_rate': 0.027988326072001492}\n",
      "Running time: 136.12247276306152 Seconds\n"
     ]
    }
   ],
   "source": [
    "from optuna import delete_study\n",
    "from optuna.exceptions import StorageInternalError\n",
    "import time\n",
    "from tensorflow.keras import layers\n",
    "start =time.time()\n",
    "\n",
    "training_condition = (X_data[:,1] == 10)|(X_data[:,1] == 12.5)|(X_data[:,1] == 15)|(X_data[:,1] == 17.5)\n",
    "training_row = np.where(training_condition)[0]\n",
    "\n",
    "validation_condition = (X_data[:,1] == 20)\n",
    "validation_row = np.where(validation_condition)[0]\n",
    "\n",
    "#train + validation\n",
    "x_train_data = X_data[training_row,:]\n",
    "y_train_data = Y_data[training_row,:]\n",
    "x_val_data = X_data[validation_row,:]\n",
    "y_val_data = Y_data[validation_row,:]\n",
    "\n",
    "#standardization\n",
    "x_train_scaled = (x_train_data - np.mean(x_train_data))/np.std(x_train_data)\n",
    "y_train_scaled = (y_train_data - np.mean(y_train_data))/np.std(y_train_data)\n",
    "x_val_scaled = (x_val_data - np.mean(x_train_data))/np.std(x_train_data)\n",
    "y_val_scaled = (y_val_data - np.mean(y_train_data))/np.std(y_train_data)\n",
    "\n",
    "tf.random.set_seed(1234)  # applied to achieve consistent results\n",
    "\n",
    "#early_stop settings\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "def create_model(trial):\n",
    "    n_layers = trial.suggest_int('n_layers', 1, 5)\n",
    "    model = tf.keras.models.Sequential()\n",
    "    for i in range(n_layers):\n",
    "        num_hidden = trial.suggest_int('n_units_{}'.format(i), 4, 64, log=True)\n",
    "        model.add(layers.Dense(num_hidden, activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
    "        dropout = trial.suggest_float('dropout_{}'.format(i), 0.1, 0.5)\n",
    "        model.add(layers.Dropout(rate=dropout))\n",
    "    model.add(layers.Dense(np.shape(Y_data)[1]))\n",
    "    \n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-1, log=True)       \n",
    "    model.compile(loss='mae',\n",
    "                  optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                  metrics=['mae', 'mse'])\n",
    "\n",
    "    return model\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    x_train = x_train_scaled\n",
    "    x_valid = x_val_scaled\n",
    "    y_train = y_train_scaled\n",
    "    y_valid = y_val_scaled  \n",
    "\n",
    "    model = create_model(trial)\n",
    "\n",
    "    model.fit(x_train, y_train,\n",
    "              callbacks=early_stop,\n",
    "              epochs=2000,\n",
    "              validation_data=(x_valid, y_valid),\n",
    "              verbose=0)\n",
    "    def r_squared(y_true, y_pred):\n",
    "        mean = np.mean(y_true)\n",
    "        total_sum_squares = np.sum((y_true - mean) ** 2)\n",
    "        residual_sum_squares = np.sum((y_true - y_pred) ** 2)\n",
    "        r2 = 1 - (residual_sum_squares / total_sum_squares)\n",
    "        return r2\n",
    "\n",
    "    score = r_squared(y_valid, model.predict(x_valid,verbose=0))\n",
    "    return score\n",
    "\n",
    "#optimization\n",
    "if __name__ == '__main__':\n",
    "    storage_name = 'sqlite:///CFD_ANN_opt.db'\n",
    "    \n",
    "    study_name='CFD_ANN_opt'\n",
    "    try:\n",
    "        delete_study(storage=storage_name, study_name=study_name)\n",
    "    except StorageInternalError:\n",
    "        pass\n",
    "    \n",
    "    study = optuna.create_study(\n",
    "        pruner=optuna.pruners.MedianPruner(n_warmup_steps=10), direction='maximize',\n",
    "        study_name=study_name, storage=storage_name, load_if_exists=False\n",
    "    )\n",
    "    study.optimize(objective, n_trials=20)\n",
    "    \n",
    "    best_params = study.best_params\n",
    "    best_value = study.best_value\n",
    "    print('\\n\\nbest_value = '+str(best_value))\n",
    "    print('best_params:')\n",
    "    print(best_params)\n",
    "\n",
    "end=time.time()\n",
    "print('Running time: %s Seconds'%(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dd6d51d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 45ms/step\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_30 (Dense)            (None, 38)                152       \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 38)                0         \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 20)                780       \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 20)                0         \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 62)                1302      \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 62)                0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 4096)              258048    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 260282 (1016.73 KB)\n",
      "Trainable params: 260282 (1016.73 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "0.8080294751198334 0.294009592327777\n",
      "[1.17 0.61 1.25 0.79 0.82 0.51 0.69 1.17 0.56 0.6  0.41 0.3  0.35 0.91\n",
      " 1.02 0.71 0.89 1.04 1.13 1.24]\n",
      "0.054202158848335\n",
      "[0.06 0.04 0.06 0.04 0.04 0.04 0.04 0.07 0.03 0.04 0.04 0.02 0.02 0.06\n",
      " 0.08 0.06 0.05 0.06 0.09 0.12]\n",
      "Running time: 9.407198190689087 Seconds\n"
     ]
    }
   ],
   "source": [
    "start =time.time()\n",
    "\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "def create_model(best_params):\n",
    "    model = Sequential()\n",
    "    for i in range(best_params['n_layers']):\n",
    "        model.add(Dense(best_params[f'n_units_{i}'], activation='relu'))\n",
    "        model.add(Dropout(best_params[f'dropout_{i}']))\n",
    "    model.add(Dense(np.shape(Y_data)[1]))\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=best_params['learning_rate'])\n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "    return model\n",
    "\n",
    "test_condition = (X_data[:,1] == 12.5)|(X_data[:,1] == 17.5)|(X_data[:,1] == 22.5)|(X_data[:,1] == 27.5)\n",
    "test_row = np.where(test_condition)[0]\n",
    "\n",
    "x_test = (X_data[test_row,:] - np.mean(x_train_data))/np.std(x_train_data)\n",
    "y_test = Y_data[test_row,:]\n",
    "\n",
    "x_train = x_train_scaled\n",
    "y_train = y_train_scaled\n",
    "\n",
    "#model training\n",
    "model = create_model(best_params)\n",
    "model.fit(x_train, y_train, epochs=2000, verbose=0)\n",
    "\n",
    "y_pred = model.predict(x_test)*np.std(y_train_data) + np.mean(y_train_data)\n",
    "\n",
    "NRMSE = []\n",
    "for i in range(x_test.shape[0]):\n",
    "    NRMSE.append((mean_squared_error(y_test[i,:], y_pred[i,:]))**0.5/(np.max(y_test[i,:])-np.min(y_test[i,:])))\n",
    "\n",
    "MAE = []\n",
    "for i in range(x_test.shape[0]):\n",
    "    MAE.append(mean_absolute_error(y_test[i,:], y_pred[i,:]))\n",
    "\n",
    "model.summary()\n",
    "print(np.mean(MAE),np.std(MAE))\n",
    "print(np.round(MAE,2))\n",
    "print(np.mean(NRMSE))\n",
    "print(np.round(NRMSE,2))\n",
    "\n",
    "end=time.time()\n",
    "\n",
    "df = pd.DataFrame(y_pred)\n",
    "df.to_excel('ANN.xlsx', index=False)\n",
    "print('Running time: %s Seconds'%(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f098cfd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
